#### Preamble ####
# Purpose: Models and tests the datasets
# Author: Chay Park
# Date: 1 March 2025 
# Contact: chay.park@mail.utoronto.ca
# License: MIT
# Pre-requisites: polars library, use the cleaned data in outputs > data > ttc_delays_ratio.csv

# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NMIrIlucaVhu2ztlOvsXNua7cW4yCRTH

# Multinomial Logistic Regression

> Can work with the outliers
"""

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Load dataset using Polars with schema override to avoid parsing errors
schema_overrides = {"Line": pl.Utf8}  # Ensure 'Line' column is treated as a string
df = pl.read_csv("ttc_delays_ratio.csv", schema_overrides=schema_overrides)

# Select relevant features and target variable
target_column = "Incident"
features = ["Day", "Min Delay/Min Gap", "Min Temp (°C)", "Mean Temp (°C)", "Total Rain (mm)", "Total Snow (cm)"]

# Encode categorical target variable
le = LabelEncoder()
y_encoded = le.fit_transform(df[target_column].to_numpy())
df = df.with_columns(pl.Series(target_column, y_encoded))

# Handle categorical features
categorical_features = ["Day"]
numerical_features = ["Min Delay/Min Gap", "Min Temp (°C)", "Mean Temp (°C)", "Total Rain (mm)", "Total Snow (cm)"]

ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
categorical_data = ohe.fit_transform(df.select(categorical_features).to_numpy())
numerical_data = df.select(numerical_features).to_numpy()

# Combine categorical and numerical features
X = np.hstack((categorical_data, numerical_data))
y = y_encoded

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train multinomial logistic regression model
model = LogisticRegression(solver='lbfgs', max_iter=500)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Print classification report with correct label matching
print(classification_report(y_test, y_pred, labels=np.unique(y_test), zero_division=0))

# Feature importance visualization
feature_importance = np.abs(model.coef_).mean(axis=0)
feature_names = ohe.get_feature_names_out(categorical_features).tolist() + numerical_features

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importance, y=feature_names)
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.xticks(rotation=45)
plt.title("Feature Importance in Multinomial Logistic Regression")
plt.show()

# Identify top incidents causing delay
y_pred_prob = model.predict_proba(X_test)
predicted_incident_indices = np.argmax(y_pred_prob, axis=1)

# Map back to original incident labels
predicted_incidents = le.inverse_transform(predicted_incident_indices)
unique, counts = np.unique(predicted_incidents, return_counts=True)
incident_counts = dict(zip(unique, counts))

# Plot top incidents causing delay
sorted_incidents = sorted(incident_counts.items(), key=lambda x: x[1], reverse=True)[:10]
incident_labels, incident_values = zip(*sorted_incidents)

plt.figure(figsize=(12, 6))
sns.barplot(x=incident_values, y=incident_labels)
plt.xlabel("Count")
plt.ylabel("Incident Type")
plt.title("Top 10 Incidents Causing Delays")
plt.show()

"""# Random Forest Regression
## Model
"""

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load dataset using Polars with schema override to handle parsing errors
schema_overrides = {"Line": pl.Utf8}  # Ensuring 'Line' is read as a string
df = pl.read_csv("ttc_delays_ratio.csv", schema_overrides=schema_overrides, infer_schema_length=10000)

# Select relevant features and target variable
target_column = "Min Delay/Min Gap"
features = ["Day", "Min Temp (°C)", "Mean Temp (°C)", "Total Rain (mm)", "Total Snow (cm)"]

# Encode categorical features
categorical_features = ["Day"]
numerical_features = ["Min Temp (°C)", "Mean Temp (°C)", "Total Rain (mm)", "Total Snow (cm)"]

ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
categorical_data = ohe.fit_transform(df.select(categorical_features).to_numpy())
numerical_data = df.select(numerical_features).to_numpy()

# Combine categorical and numerical features
X = np.hstack((categorical_data, numerical_data))
y = df[target_column].to_numpy()

# Split into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train Random Forest Regression model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)

# Model evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")
print(f"R-squared: {r2:.2f}")

# Feature importance visualization with sorted values
feature_importance = rf_model.feature_importances_
feature_names = ohe.get_feature_names_out(categorical_features).tolist() + numerical_features
sorted_idx = np.argsort(feature_importance)

plt.figure(figsize=(12, 6))
sns.barplot(x=feature_importance[sorted_idx], y=np.array(feature_names)[sorted_idx], orient="h")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.title("Feature Importance in Random Forest Regression (Sorted)")
plt.show()

# Enhanced Scatter plot of actual vs predicted values with density contours
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)
sns.kdeplot(x=y_test, y=y_pred, cmap="Reds", fill=True, alpha=0.3)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='dashed', label='Perfect Fit')
plt.xlabel("Actual Delay")
plt.ylabel("Predicted Delay")
plt.title("Actual vs Predicted Delay - Random Forest Regression")
plt.legend()
plt.show()

# Prediction Insights
print("\nPrediction Insights:")
print("1. The Random Forest model predicts the delay times based on historical data.")
print("2. The R-squared value (R²) indicates how well the model explains the variance in delay times.")
print("   - R² close to 1: Strong predictive power.")
print("   - R² close to 0: Weak predictive power, suggesting feature engineering is needed.")
print("3. Sorted feature importance helps identify key contributors to delay prediction.")
print("4. The enhanced scatter plot with density contours highlights areas where predictions are clustered.")

# Possible Next Steps if Model Performance is Low
if r2 < 0.2:
    print("\n**Next Steps for Improvement:**")
    print("- Consider adding more relevant features such as traffic congestion levels or incidents.")
    print("- Explore different machine learning models (e.g., Gradient Boosting, Neural Networks).")
    print("- Perform hyperparameter tuning to optimize the model.")
    print("- Handle potential outliers in the dataset.")

"""Define the function. Run the test data input"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder

# Define categorical columns
categorical_cols = ["Line", "Day", "Location", "Incident", "Bound", "Vehicle", "Type"]
label_encoders = {col: LabelEncoder() for col in categorical_cols}

# Load dataset
df = pd.read_csv("ttc_delays_ratio.csv")

# Encode categorical columns
for col in categorical_cols:
    df[col] = label_encoders[col].fit_transform(df[col])

# Prepare features and target
X = df.drop(columns=["Min Delay/Min Gap", "Date", "Time"])
y = df["Min Delay/Min Gap"]

# Train Random Forest Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X, y)

def predict_delay(test_data):
    """
    Predicts the 'Min Delay/Min Gap' ratio for given test data.

    Parameters:
    - test_data (dict): Dictionary with feature names as keys and values as inputs.

    Returns:
    - float: Predicted 'Min Delay/Min Gap' ratio.
    """
    # Convert categorical values using label encoders
    for col in categorical_cols:
        if col in test_data:
            if test_data[col] in label_encoders[col].classes_:
                test_data[col] = label_encoders[col].transform([test_data[col]])[0]
            else:
                test_data[col] = -1  # Assign unknown labels to -1

    # Create a DataFrame for prediction
    test_df = pd.DataFrame([test_data])

    # Ensure the same feature order as training data
    test_df = test_df[X.columns]

    # Predict
    prediction = rf_model.predict(test_df)[0]
    return prediction

# Sample test input
test_sample = {
    "Line": np.random.choice(df["Line"].unique()),
    "Day": np.random.choice(df["Day"].unique()),
    "Location": np.random.choice(df["Location"].unique()),
    "Incident": np.random.choice(df["Incident"].unique()),
    "Min Delay": np.random.randint(0, 30),
    "Min Gap": np.random.randint(10, 60),
    "Bound": np.random.choice(df["Bound"].unique()),
    "Vehicle": np.random.choice(df["Vehicle"].unique()),
    "Max Temp (°C)": np.random.uniform(-10, 30),
    "Min Temp (°C)": np.random.uniform(-10, 30),
    "Mean Temp (°C)": np.random.uniform(-10, 30),
    "Total Rain (mm)": np.random.uniform(0, 50),
    "Total Snow (cm)": np.random.uniform(0, 50),
    "Type": np.random.choice(df["Type"].unique()),
}

# Run the test
predicted_value = predict_delay(test_sample)
print("Test Sample:", test_sample)
print("Predicted Min Delay/Min Gap:", predicted_value)
